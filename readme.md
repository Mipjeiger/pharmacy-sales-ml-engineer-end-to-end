![alt text](<images/ml engineer pharmacy workflow.png>)

# ğŸ§ªğŸ’Š Pharmacy Machine Learning Engineer â€“ End-to-End Workflow

This repository demonstrates a **production-ready, end-to-end Machine Learning workflow** for pharmacy analytics, covering data ingestion, feature engineering, model training, orchestration, monitoring, and alerting.

---

## ğŸ—ï¸ Architecture Overview

The system is designed using **modern ML engineering best practices**, ensuring scalability, reproducibility, and observability across the entire pipeline.

---

## ğŸ”„ End-to-End Workflow Explanation

### ğŸ“¥ 1. Data Sources & Ingestion
Raw pharmacy data (e.g. sales, transactions, pricing) is collected from:
- ğŸ“„ CSV files  
- ğŸ”„ Upstream operational systems  

Data ingestion is handled using **Kafka**, enabling both **batch** and **real-time streaming** ingestion.

---

### ğŸ—„ï¸ 2. PostgreSQL â€“ Source of Truth
All ingested data is stored in **PostgreSQL**, which acts as the **single source of truth**:
- Raw data persistence  
- Data validation  
- Historical consistency  

---

### ğŸ§© 3. Feature Engineering (SQL)
Using **SQL transformations**, raw data is converted into **ML-ready feature tables**, such as:
- Aggregated sales metrics  
- Price statistics  
- Time-based features  

These feature tables are optimized for training and reproducibility.

---

### ğŸ› ï¸ 4. Orchestration with Airflow
**Apache Airflow** orchestrates the entire pipeline through DAGs that manage:
- â° Scheduled data ingestion  
- ğŸ” Feature table generation  
- ğŸš€ Model training triggers  
- ğŸ”— Task dependencies  

Kafka events can also act as **real-time triggers** for Airflow DAG execution.

---

### ğŸ¤– 5. Model Training (`train.py`)
Once features are available, Airflow triggers the **`train.py`** script:
- Loads features from PostgreSQL  
- Trains the machine learning model  
- Evaluates performance metrics  

This stage represents the **core ML engineering logic**.

---

### ğŸ“Š 6. Experiment Tracking & Model Registry (MLflow)
All experiments are logged to **MLflow**, including:
- ğŸ“ˆ Metrics  
- âš™ï¸ Hyperparameters  
- ğŸ“¦ Model artifacts  

MLflow also manages **model versioning**, ensuring full traceability and reproducibility.

---

### ğŸ³ 7. Containerization (Docker)
The pipeline runs inside **Docker containers**, providing:
- Environment consistency  
- Reproducible training runs  
- Easier deployment across environments  

---

### ğŸ“¡ 8. Monitoring & Observability
System and pipeline health are monitored using **Grafana**, enabling:
- ğŸ“Š Resource monitoring  
- ğŸ” Pipeline observability  
- ğŸš¨ Early issue detection  

---

### ğŸ”” 9. Notifications & Alerts (Slack)
**Slack alerts** notify stakeholders in real time about:
- âœ… Successful pipeline runs  
- âŒ Airflow DAG failures  
- ğŸ§  Model training completion  

---

## âœ… Summary

This project demonstrates an **enterprise-grade ML engineering workflow** where:

- ğŸ”„ Kafka handles ingestion and triggers  
- ğŸ—„ï¸ PostgreSQL ensures reliable data storage  
- ğŸ§© SQL enables feature engineering  
- ğŸ› ï¸ Airflow orchestrates pipelines  
- ğŸ“Š MLflow tracks experiments and models  
- ğŸ³ Docker guarantees reproducibility  
- ğŸ“¡ Grafana provides monitoring  
- ğŸ”” Slack delivers operational alerts  

---

## ğŸ¯ Target Use Case
- Pharmacy sales analytics  
- Demand forecasting  
- Price sensitivity analysis  
- ML production pipeline design  

---

## ğŸ‘¨â€ğŸ’» Role Alignment
This workflow reflects real-world responsibilities of a:
- **Machine Learning Engineer**
- **Data Engineer (ML-focused)**
- **MLOps Engineer**

---

> ğŸš€ Built with scalability, observability, and production readiness in mind.
